{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e25589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0954f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "QRNG shape: (390, 256) Label: (390,)\n",
      "PRNG shape: (390, 256) Label: (390,)\n",
      "Total X shape: (780, 256) | y shape: (780,)\n",
      "Label distribution: (array([0., 1.], dtype=float32), array([390, 390], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== Load Data ==========\n",
    "def load_chunks(file_path, label, chunk_size=256, max_chunks=390):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read().replace('\\n', '').strip()\n",
    "    data = [int(b) for b in data]\n",
    "    chunks = []\n",
    "    labels = []\n",
    "    for i in range(0, len(data) - chunk_size + 1, chunk_size):\n",
    "        chunks.append(data[i:i + chunk_size])\n",
    "        labels.append(label)\n",
    "        if len(chunks) >= max_chunks:\n",
    "            break\n",
    "    return np.array(chunks, dtype=np.float32), np.array(labels, dtype=np.float32)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_qrng, y_qrng = load_chunks('qrng_1.txt', 1.0)\n",
    "X_prng, y_prng = load_chunks('prng_2.txt', 0.0)\n",
    "print(\"QRNG shape:\", X_qrng.shape, \"Label:\", y_qrng.shape)\n",
    "print(\"PRNG shape:\", X_prng.shape, \"Label:\", y_prng.shape)\n",
    "print(\"Total X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "print(\"Label distribution:\", np.unique(y, return_counts=True))\n",
    "\n",
    "X = np.concatenate([X_qrng, X_prng])\n",
    "y = np.concatenate([y_qrng, y_prng])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93b555df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "# ========== Define ANN Model ==========\n",
    "class DeepEntropyANN(nn.Module):\n",
    "    def __init__(self, input_size=256):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbad39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Training Setup ==========\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DeepEntropyANN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ========== Train and Evaluate ==========\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device).unsqueeze(1)\n",
    "            preds = model(xb)\n",
    "            preds = (preds > 0.5).float()\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b9524d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1 | Loss: 0.5447 | Accuracy: 0.5064\n",
      "Epoch 2 | Loss: 0.4959 | Accuracy: 0.5064\n",
      "Epoch 3 | Loss: 0.4391 | Accuracy: 0.5064\n",
      "Epoch 4 | Loss: 0.3948 | Accuracy: 0.5321\n",
      "Epoch 5 | Loss: 0.3492 | Accuracy: 0.5385\n",
      "Epoch 6 | Loss: 0.3075 | Accuracy: 0.4808\n",
      "Epoch 7 | Loss: 0.2407 | Accuracy: 0.5192\n",
      "Epoch 8 | Loss: 0.2029 | Accuracy: 0.5192\n",
      "Epoch 9 | Loss: 0.1504 | Accuracy: 0.5256\n",
      "Epoch 10 | Loss: 0.1210 | Accuracy: 0.5064\n"
     ]
    }
   ],
   "source": [
    "# ========== Run Training ==========\n",
    "print(\"Training...\")\n",
    "for epoch in range(10):\n",
    "    loss = train(model, train_loader)\n",
    "    acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss:.4f} | Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2061598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_binary_string(file_path, chunk_size=256):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read().replace('\\n', '').strip()\n",
    "    data = [int(b) for b in data[:chunk_size]]  # use only 1000 bits\n",
    "    return torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7421c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.6316 (closer to 1 = QRNG, closer to 0 = PRNG)\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model (if not already in memory)\n",
    "model.eval()  # put model in evaluation mode\n",
    "\n",
    "# Load the test string from file\n",
    "x_test = load_binary_string('prng_1.txt')  # new file here\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test).item()\n",
    "\n",
    "print(f\"Prediction: {pred:.4f} (closer to 1 = QRNG, closer to 0 = PRNG)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
